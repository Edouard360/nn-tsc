{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Concatenate, Conv1D, MaxPool1D, Activation, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from callbacks import SoftVerbose\n",
    "from layers import ConvDiff, AutoReshape\n",
    "from tools import train_test_ucr\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "#config.gpu_options.allow_growth=True\n",
    "#set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9d4b38edfca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5,\n\u001b[1;32m     52\u001b[0m                                   patience=50, min_lr=0.0001)\n\u001b[0;32m---> 53\u001b[0;31m     hist = model.fit(x_train, Y_train, batch_size=batch_size, epochs=epochs,\n\u001b[0m\u001b[1;32m     54\u001b[0m                      verbose=0, validation_data=(x_test, Y_test), callbacks=[reduce_lr, soft_verbose])  # ,tensorboard])\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# flist = ['Adiac', 'Beef', 'CBF', 'ChlorineConcentration', 'CinC_ECG_torso', 'Coffee', 'Cricket_X', 'Cricket_Y', 'Cricket_Z',\n",
    "# 'DiatomSizeReduction', 'ECGFiveDays', 'FaceAll', 'FaceFour', 'FacesUCR', '50words', 'FISH', 'Gun_Point', 'Haptics',\n",
    "# 'InlineSkate', 'ItalyPowerDemand', 'Lighting2', 'Lighting7', 'MALLAT', 'MedicalImages', 'MoteStrain', 'NonInvasiveFatalECG_Thorax1',\n",
    "# 'NonInvasiveFatalECG_Thorax2', 'OliveOil', 'OSULeaf', 'SonyAIBORobotSurface', 'SonyAIBORobotSurfaceII', 'StarLightCurves', 'SwedishLeaf', 'Symbols',\n",
    "# 'synthetic_control', 'Trace', 'TwoLeadECG', 'Two_Patterns', 'uWaveGestureLibrary_X', 'uWaveGestureLibrary_Y', 'uWaveGestureLibrary_Z', 'wafer', 'WordsSynonyms', 'yoga']\n",
    "\n",
    "fdir = \"./ucr/\"\n",
    "flist = ['Beef']\n",
    "\n",
    "epochs = 1000\n",
    "soft_verbose = SoftVerbose()\n",
    "# tensorboard = TensorBoard(log_dir = './logs',write_graph=True,write_images=True)\n",
    "\n",
    "for each in flist:\n",
    "    fname = each\n",
    "    x_train, Y_train, x_test, Y_test, nb_classes = train_test_ucr(fdir, fname)\n",
    "    batch_size = max(min(int(x_train.shape[0] / 10), 16), 64)\n",
    "\n",
    "    x = keras.layers.Input(x_train.shape[1:])\n",
    "    #    drop_out = Dropout(0.2)(x)\n",
    "\n",
    "    x_ = ConvDiff()(x)\n",
    "    x__ = Concatenate(axis=2)([x_, x])\n",
    "    conv1 = Conv1D(16, 8, padding='same')(x__)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "\n",
    "    #    drop_out = Dropout(0.2)(conv1)\n",
    "    conv2 = Conv1D(32, (5), padding='same')(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "\n",
    "    #    drop_out = Dropout(0.2)(conv2)\n",
    "    conv3 = Conv1D(16, (3), padding='same')(conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    # full = keras.layers.GlobalMaxPooling2D()(conv3)\n",
    "\n",
    "    full = keras.layers.pooling.MaxPool1D(pool_size=5, strides=5, padding=\"valid\")(conv3)\n",
    "    full = AutoReshape()(full)\n",
    "\n",
    "    out = Dense(nb_classes, activation='softmax')(full)\n",
    "\n",
    "    model = Model(inputs=x, outputs=out)\n",
    "    json_string = model.to_json()\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    # model.load_weights('./models/' + fname + '.h5')\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5,\n",
    "                                  patience=50, min_lr=0.0001)\n",
    "    hist = model.fit(x_train, Y_train, batch_size=batch_size, epochs=epochs,\n",
    "                     verbose=0, validation_data=(x_test, Y_test), callbacks=[reduce_lr, soft_verbose])  # ,tensorboard])\n",
    "\n",
    "    # model.save_weights('./models/' + fname + '.h5')\n",
    "    # Print the testing results which has the lowest training loss.\n",
    "    log = pd.DataFrame(hist.history)\n",
    "    print(log.loc[log['loss'].idxmin]['loss'], log.loc[log['loss'].idxmin]['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}