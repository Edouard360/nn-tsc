{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: edouard\n",
    "\"\"\"\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Concatenate, Conv1D, MaxPool1D, Activation, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from callbacks import SoftVerbose\n",
    "from layers import ConvDiff, AutoReshape\n",
    "from tools import train_test_ucr, initialize_dataframe, get_ucr_list\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "# config.gpu_options.allow_growth=True\n",
    "# set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fdir = \"./ucr/\"\n",
    "flist = get_ucr_list()\n",
    "\n",
    "soft_verbose = SoftVerbose()\n",
    "# tensorboard = TensorBoard(log_dir = './logs',write_graph=True,write_images=True)\n",
    "dataframe = initialize_dataframe(\"logs/results.csv\")\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for each in flist:\n",
    "    fname = each\n",
    "    x_train, Y_train, x_test, Y_test, nb_classes = train_test_ucr(fdir, fname)\n",
    "    batch_size = max(min(int(x_train.shape[0] / 10), 16), 64)\n",
    "    x = keras.layers.Input(x_train.shape[1:])\n",
    "    #    drop_out = Dropout(0.2)(x)\n",
    "\n",
    "    x_diff = ConvDiff()(x)\n",
    "    x_combined = Concatenate(axis=2)([x_diff, x])\n",
    "    conv1 = Conv1D(16, 8, padding='same')(x_combined)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "\n",
    "    #    drop_out = Dropout(0.2)(conv1)\n",
    "    conv2 = Conv1D(32, (5), padding='same')(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "\n",
    "    #    drop_out = Dropout(0.2)(conv2)\n",
    "    conv3 = Conv1D(16, (3), padding='same')(conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    # full = keras.layers.GlobalMaxPooling2D()(conv3)\n",
    "\n",
    "    full = keras.layers.pooling.MaxPool1D(pool_size=5, strides=5, padding=\"valid\")(conv3)\n",
    "    full = AutoReshape()(full)\n",
    "\n",
    "    out = Dense(nb_classes, activation='softmax')(full)\n",
    "\n",
    "    model = Model(inputs=x, outputs=out)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    # model.load_weights('./models/' + fname + '.h5')\n",
    "    # json_string = model.to_json()\n",
    "    # plot_model(model, to_file='./model.png')\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5,\n",
    "                                  patience=50, min_lr=0.0001)\n",
    "    hist = model.fit(x_train, Y_train, batch_size=batch_size, epochs=epochs,\n",
    "                     verbose=0, validation_data=(x_test, Y_test), callbacks=[reduce_lr, soft_verbose])  # ,tensorboard])\n",
    "\n",
    "    # model.save_weights('./models/' + fname + '.h5')\n",
    "    # Print the testing results which has the lowest training loss.\n",
    "\n",
    "    log = pd.DataFrame(hist.history)\n",
    "    best_val_acc = np.round(log.loc[log['val_acc'].idxmax]['val_acc'], 2)\n",
    "    final_val_acc = np.round(log.loc[log['loss'].idxmin]['val_acc'], 2)\n",
    "    dataframe.ix[fname, :] = best_val_acc, final_val_acc\n",
    "    print(\"For dataset %s\\nBest test accuracy: %.2f\\nFinal accuracy: %.2f\\n\" % (fname, best_val_acc, final_val_acc))\n",
    "    dataframe.to_csv(dataframe.path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
